\chapter{Introducción}
\section{Lenguaje de programación \textit{R}}
\textit{R} es un lenguje de programación nacido como la versión libre de \textit{S} creado en los Laboratorios Bell a finales de la década de los 70 para satisfacer la necesidad de realizar cómputo estadístico de una manera más interactiva que Fortran.\cite{S}\\
\textit{R} al igual que todas sus librerías implementan una gran variedad de técnicas estadísticas que incluyen pero no están limitadas a modelos lineales y no lineales, análisis de series de tiempo y clasificación. Es por esto que en la actualidad es una de las herramientas más utilizadas en la ciencia de datos.

\section{Base de Datos}
Las fuentes de datos de las que se habló en el entregable anterior fueron ordenadas en dos tipos de bases de datos:\\
\begin{itemize}
    \item Postgres\cite{PostgreSQL}
    \item Athena\cite{Athena}
\end{itemize}
Ambas pertencecen a un tipo de bases consideradas relacionales, que tienen una naturaleza columnar y la manera de interactuar con ellas es por medio del lenguaje SQL\cite{SQL} (Structured Query Language) el cual está ampliamente extendido para este tipo de consultas aunque cada uno tiene soportes para diferentes tipos de objetos y se rige por su propio dialecto, es decir no usan un tipo de SQL estándar sino que existen difieren en funciones y tipo de llamados.\\
La infraestructura de la base de datos Postgres está montada sobre el servicio de Amazon AWS llamado RDS, que consta de software de bases de datos que se encuentran en instancias EC2 optimizadas para el uso de este tipo de necesidades, además de estar completamente manejados por lo que no es necesario configuar los detalles técnicos.\\
Por otro lado, Athena es otro servicio de AWS que permite hacer consultas sobre archivos estructurados alojados en S3 (de lo que se habló en el primer entregable) el cual monta un cluster efímero de instancias y ejecuta la consulta de forma paralela gracias a la tecnología HIVE de Apache\cite{Apache}.

\subsection{Apache Hadoop}
Hadoop\cite{hadoop} es una forma de acceder a ciertos sistemas de archivos soportados los cuales  pueden ser leídos y procesados de forma distribuida, lo que brinda la oportunidad de analizar grandes cantidades de datos. Un clúster típico Hadoop incluye un nodo maestro y múltiples trabajadores. El maestro realiza un rastreador de trabajo llamado jobtracker, uno de tareas llamado tasktracker, un nodo de nombres (namenode) y uno de datos (datanode). Los trabajadores sólo tienen nodo de datos y rastreador de tareas. Al correr sobre Java, se necesita tener instalado JRE y SSH para tener comunicación entre los nodos.

\subsection{Apache Hive}
Hive es una infraestructura indexada de agrupación, consulta y análisis de datos que está construida sobre Hadoop. Otras características de Hive son:
\begin{itemize}
    \item Indexación compacta o bitmaps para proporcionar aceleración en consultas.
    \item Soporte para distintos tipos de almacenamiento de texto como:
        \begin{itemize}
            \item RCFile
            \item HBase
            \item ORC
            \item Parquet
        \end{itemize}
    \item Almacenamiento de metadatos en bases de datos relacionales, lo que permite reducir el tiempo para realizar verificaciones semánticas durante la ejecución de consultas.
    \item Operaciones sobre datos comprimidos almacenados en ecosistema Hadoop con algoritmos como:
        \begin{itemize}
            \item DEFLATE
            \item BWT
            \item Snappy
        \end{itemize}
    \item UDF (Funciones definidas por el usario)
    \item Consultas estilo SQL (HiveQL)
\end{itemize}
